{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from niapy.algorithms.basic import ParticleSwarmAlgorithm, DifferentialEvolution, FireflyAlgorithm, GeneticAlgorithm\n",
    "from niapy.algorithms.modified import SelfAdaptiveDifferentialEvolution\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from tabulate import tabulate\n",
    "\n",
    "from dataloaders.tabular import TabularDataset\n",
    "from experiments.dnn_ae_experiment import DNNAEExperiment\n",
    "from models.dnn_ae import Autoencoder\n",
    "from niapy_extension.wrapper import *\n",
    "from storage.database import SQLiteConnector\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_UUID = uuid.uuid4().hex\n",
    "\n",
    "with open(\"configs/dnn_ae.yaml\", 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "config['logging_params']['save_dir'] += RUN_UUID + '/'\n",
    "Path(config['logging_params']['save_dir']).mkdir(parents=True, exist_ok=True)\n",
    "seed_everything(config['exp_params']['manual_seed'], True)\n",
    "datamodule = TabularDataset(**config[\"data_params\"], pin_memory=True)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "solution = [0.0, 1.0, 0.3238545402477898, 0.0, 0.2770718202737109, 0.6741137338475078, 1.0]\n",
    "solution = numpy.array(solution)\n",
    "model = Autoencoder(solution, **config)\n",
    "saving_path = config['logging_params']['save_dir'] + \"manual_alg_\" + model.hash_id\n",
    "Path(saving_path).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=config['early_stop']['monitor'],\n",
    "                                    min_delta=config['early_stop']['min_delta'],\n",
    "                                    patience=config['early_stop']['patience'],\n",
    "                                    verbose=False,\n",
    "                                    check_finite=True,\n",
    "                                    mode=\"max\")\n",
    "\n",
    "experiment = DNNAEExperiment(model, config['exp_params'], config['model_params']['n_features'])\n",
    "config['trainer_params']['max_epochs'] = model.num_epochs\n",
    "tb_logger = TensorBoardLogger(save_dir=config['logging_params']['save_dir'],\n",
    "                              name=\"manual_alg_\" + model.hash_id)\n",
    "\n",
    "runner = Trainer(logger=tb_logger,\n",
    "                 enable_progress_bar=False,\n",
    "                 # accelerator=\"gpu\",\n",
    "                 # devices=1,\n",
    "                 # auto_select_gpus=True,\n",
    "                 callbacks=[\n",
    "                     LearningRateMonitor(),\n",
    "                     ModelCheckpoint(save_top_k=1,\n",
    "                                     dirpath=os.path.join(tb_logger.log_dir, \"checkpoints\"),\n",
    "                                     monitor=\"val_loss\",\n",
    "                                     save_last=True),\n",
    "                     early_stop_callback,\n",
    "                 ],\n",
    "                 # strategy=DDPPlugin(find_unused_parameters=False),\n",
    "                 **config['trainer_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and save mode to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"======= Training {config['model_params']['name']} =======\")\n",
    "print(f'\\nTraining start: {datetime.now().strftime(\"%H:%M:%S-%d/%m/%Y\")}')\n",
    "runner.fit(experiment, datamodule=datamodule)\n",
    "print(f'\\nTraining end: {datetime.now().strftime(\"%H:%M:%S-%d/%m/%Y\")}')\n",
    "torch.save(model.state_dict(), saving_path + \"/manual_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(solution, **config)\n",
    "model.load_state_dict(torch.load(saving_path + \"/manual_model.pt\"))\n",
    "#model.load_state_dict(torch.load(\"logs/add5e7b369a2493e9ec39f428d4c05fd/ParticleSwarmAlgorithm_e1b93f7da8ebc4a6cb5b2084e8c4f7d272b923c4.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict with loaded model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the model\n",
    "dataloader_iterator = iter(datamodule.test_dataloader())\n",
    "rmse_list = list()\n",
    "counter = 0\n",
    "for data, target in dataloader_iterator:\n",
    "    data = data.to('cpu')\n",
    "    reconstructed, input =  model.forward(data)\n",
    "    rmse = mean_squared_error(input.detach().numpy(), reconstructed.detach().numpy(), squared=True)\n",
    "    rmse_list.append(rmse)\n",
    "    counter +=1\n",
    "\n",
    "print(counter)\n",
    "print(f\"Number of elements: {len(rmse_list)}\")\n",
    "print(sum(rmse_list) / len(rmse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate AUC value based on anomaly detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from experiments.anomalyDetection import AnomalyDetection\n",
    "\n",
    "anomaly_detection = AnomalyDetection([0], [1])\n",
    "dataloader_iterator = iter(datamodule.test_dataloader())\n",
    "\n",
    "inputs = []\n",
    "reconstructs = []\n",
    "reconstrcution_errors = []\n",
    "instance_number = []\n",
    "instance_target = []\n",
    "targets = []\n",
    "\n",
    "index = 0\n",
    "for data, target in dataloader_iterator:\n",
    "    data = data.to('cpu')\n",
    "    reconstructed, input = model.forward(data)\n",
    "\n",
    "\n",
    "\n",
    "    for x, y, z in zip(reconstructed, input, target):\n",
    "        inputs.append(x)\n",
    "        reconstructs.append(y)\n",
    "        targets.append(z)\n",
    "        reconstructed, input = model.forward(data)\n",
    "        rmse = mean_squared_error(input.detach().numpy(), reconstructed.detach().numpy(), squared=True)\n",
    "        reconstrcution_errors.append(rmse)\n",
    "        instance_number.append(index)\n",
    "        instance_target.append(z.item())\n",
    "        index +=1\n",
    "\n",
    "anomaly_detection.find(inputs, reconstructs, targets)\n",
    "\n",
    "AUC = anomaly_detection.AUC\n",
    "print(f\"Model AUC score: {anomaly_detection.AUC}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(y_test, FPR_array, TPR_array, view=False, filename='./logs/roc_curve.png'):\n",
    "    # https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n",
    "    random_probs = [0 for i in range(len(y_test))]\n",
    "    p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "\n",
    "    # This is the ROC curve\n",
    "    plt.style.use('seaborn')\n",
    "    # FPR_array = [ round(elem, 2) for elem in FPR_array ]\n",
    "    # TPR_array = [ round(elem, 2) for elem in TPR_array ]\n",
    "    # plot roc curves\n",
    "    plt.plot(FPR_array, TPR_array, linestyle='-', color='green', label='Autoencoder')\n",
    "    plt.plot(p_fpr, p_tpr, linestyle='--', color='blue', label='Random')\n",
    "\n",
    "    plt.title(f'ROC curve - AUC: {round(np.trapz(TPR_array, FPR_array), 3)}')\n",
    "    # x label\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    # y label\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(filename)\n",
    "\n",
    "    if view:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "plot_roc_curve(targets, anomaly_detection.FPR_array, anomaly_detection.TPR_array, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2D Scatter plot (anomalies vs. normal)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datamodule = TabularDataset(**config[\"data_params\"], pin_memory=True)\n",
    "datamodule.setup()\n",
    "x = datamodule.test_dataset.x_test.cpu().detach().numpy()\n",
    "y = datamodule.test_dataset.y_test.cpu().detach().numpy()\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/dimension-reduction-techniques-with-python-f36ca7009e5c\n",
    "X_tsne = TSNE(n_components=2, learning_rate=1000, n_iter=1000, perplexity=60).fit_transform(x)\n",
    "X_pca = PCA().fit_transform(x)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y[:x.shape[0]], cmap='cool')\n",
    "plt.savefig('scatter2D.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/dimension-reduction-techniques-with-python-f36ca7009e5c\n",
    "X_tsne = TSNE(n_components=2, learning_rate=1000, n_iter=1000, perplexity=200).fit_transform(x)\n",
    "X_pca = PCA().fit_transform(x)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y[:x.shape[0]], cmap='cool')\n",
    "plt.savefig('scatter2D.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3D Scatter plot (anomalies vs. normal)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_tsne = TSNE(n_components=3,learning_rate=250, n_iter=1000, perplexity=10).fit_transform(x)\n",
    "X_pca = PCA().fit_transform(x)\n",
    "ax = plt.axes(projection='3d')\n",
    "# Data for a three-dimensional line\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = X_tsne[:, 0]\n",
    "xdata = X_tsne[:, 1]\n",
    "ydata = X_tsne[:, 2]\n",
    "ax.set_proj_type('ortho')\n",
    "ax.scatter3D(xdata, ydata, zdata, c=y[:x.shape[0]],cmap='cool')\n",
    "plt.savefig('scatter3D.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(reconstrcution_errors, instance_target)),columns =['Error', 'Class'])\n",
    "sns.boxplot( y=df[\"Error\"], x=df[\"Class\"] );\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
